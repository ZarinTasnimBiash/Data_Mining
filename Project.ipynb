{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JaHaYCPIuxp8"
      },
      "outputs": [],
      "source": [
        "# Zarin Tasnim Biash\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.cluster import AgglomerativeClustering, KMeans, DBSCAN\n",
        "from sklearn.metrics import silhouette_score\n",
        "import scipy.cluster.hierarchy as shc\n",
        "\n",
        "\n",
        "coverage = pd.read_csv('/content/coverage.csv')\n",
        "mortality = pd.read_csv('/content/mortality.csv')\n",
        "prevalence = pd.read_csv('/content/prevalence.csv')\n",
        "screening_method = pd.read_csv('/content/screening_method.csv')\n",
        "disability_adjusted_life_yrs = pd.read_csv('/content/disability_adjusted_life_years.csv')\n",
        "years_lived_with_disability = pd.read_csv('/content/Years_lived_with_disability.csv')\n",
        "years_lost_with_disability = pd.read_csv('/content/Years_lost_with_disability.csv')\n",
        "prevalence_of_cancer = pd.read_csv('/content/prevalence_of_cancer.csv')\n",
        "incidence_of_cancer = pd.read_csv('/content/incidence_of_cancer.csv')\n",
        "\n",
        "# print(coverage.head())\n",
        "# print(mortality.head())\n",
        "# print(prevalence.head())\n",
        "# print(screening_method.head())\n",
        "\n",
        "\n",
        "# Standardize Location name value\n",
        "def output (filepath: str, data):\n",
        "    data.to_csv(filepath, sep=',', header=True, index=False)\n",
        "\n",
        "location_id_unique = mortality['location_id'].unique()\n",
        "location_unique = []\n",
        "for location_id in location_id_unique:\n",
        "    location_name = ''\n",
        "    for id in mortality.index:\n",
        "        if location_id == mortality.loc[id, 'location_id']:\n",
        "            location_name = mortality.loc[id, 'location_name']\n",
        "            break\n",
        "    location_unique.append([location_id, location_name])\n",
        "# print(location_unique)\n",
        "\n",
        "for location in location_unique:\n",
        "  for id in prevalence_of_cancer.index:\n",
        "      if location[0] == prevalence_of_cancer.loc[id, 'location_id']:\n",
        "          prevalence_of_cancer.loc[id, 'location_name'] = location[1]\n",
        "  for id in incidence_of_cancer.index:\n",
        "      if location[0] == incidence_of_cancer.loc[id, 'location_id']:\n",
        "          incidence_of_cancer.loc[id, 'location_name'] = location[1]\n",
        "  for id in years_lived_with_disability.index:\n",
        "      if location[0] == years_lived_with_disability.loc[id, 'location_id']:\n",
        "          years_lived_with_disability.loc[id, 'location_name'] = location[1]\n",
        "  for id in years_lost_with_disability.index:\n",
        "      if location[0] == years_lost_with_disability.loc[id, 'location_id']:\n",
        "          years_lost_with_disability.loc[id, 'location_name'] = location[1]\n",
        "  for id in disability_adjusted_life_yrs.index:\n",
        "      if location[0] == disability_adjusted_life_yrs.loc[id, 'location_id']:\n",
        "          disability_adjusted_life_yrs.loc[id, 'location_name'] = location[1]\n",
        "\n",
        "# Coverage Dataset\n",
        "coverage_cleaned = coverage.dropna(axis=1, how='all')\n",
        "coverage_cleaned = coverage_cleaned[coverage_cleaned['Period'] == 2019]\n",
        "coverage_columns_to_drop = ['Period', 'IndicatorCode', 'Indicator', 'ValueType', 'ParentLocationCode', 'ParentLocation', 'Location type', 'SpatialDimValueCode', 'Period type', 'IsLatestYear', 'FactValueTranslationID', 'FactComments', 'Language', 'DateModified']\n",
        "coverage_cleaned = coverage_cleaned.drop(columns=coverage_columns_to_drop)\n",
        "\n",
        "coverage_cleaned.rename(columns={'FactValueNumericLow': 'CoverageFactValueNumericLow', 'FactValueNumericHigh': 'CoverageFactValueNumericHigh', 'Value': 'CoverageValue'}, inplace=True)\n",
        "\n",
        "# print(coverage_cleaned.head())\n",
        "coverage_cleaned.to_csv('coverage_cleaned.csv', index=False)\n",
        "\n",
        "# Mortality Dataset\n",
        "mortality_cleaned = mortality[mortality['metric_name'] == 'Percent']\n",
        "mortality_columns_to_drop = ['measure_name', 'metric_id', 'measure_id', 'location_id', 'sex_id', 'upper', 'lower', 'sex_name', 'cause_id', 'year', 'metric_name', 'cause_name', 'age_id']\n",
        "mortality_cleaned = mortality_cleaned.drop(columns=mortality_columns_to_drop)\n",
        "mortality_cleaned.rename(columns={'location_name': 'Location', 'val': 'Mortality_val'}, inplace=True)\n",
        "# print(mortality_cleaned.head())\n",
        "mortality_cleaned.to_csv('mortality_cleaned.csv', index=False)\n",
        "\n",
        "# Prevalence Dataset\n",
        "prevalence_cleaned = prevalence.dropna(axis=1, how='all')\n",
        "prevalence_cleaned = prevalence_cleaned[prevalence_cleaned['Period'] == 2019]\n",
        "prevalence_cleaned = prevalence_cleaned[prevalence_cleaned['Dim3'] == 'in lifetime']\n",
        "prevalence_columns_to_drop = ['Period', 'IndicatorCode', 'Indicator', 'ValueType', 'ParentLocationCode', 'Value', 'FactValueNumericHigh', 'FactValueNumericLow', 'ParentLocation', 'Location type', 'SpatialDimValueCode', 'Period type', 'Period', 'Language', 'DateModified', 'IsLatestYear', 'Dim1 type', 'Dim1', 'Dim1ValueCode', 'Dim2 type', 'Dim2', 'Dim2ValueCode', 'Dim3 type', 'Dim3', 'Dim3ValueCode']\n",
        "prevalence_cleaned = prevalence_cleaned.drop(columns=prevalence_columns_to_drop)\n",
        "prevalence_cleaned.rename(columns={'FactValueNumeric':'PrevalenceFactValueNumeric'}, inplace=True)\n",
        "# print(prevalence_cleaned.head())\n",
        "prevalence_cleaned.to_csv('prevalence_cleaned.csv', index=False)\n",
        "\n",
        "# Screening Dataset\n",
        "screening_method_cleaned = screening_method.dropna(axis=1, how='all')\n",
        "# Drop rows where year!=2019 and only keep 2019 rows\n",
        "screening_method_cleaned = screening_method_cleaned[screening_method_cleaned['Period'] == 2019]\n",
        "screening_method_columns_to_drop = ['Period', 'IndicatorCode', 'Indicator', 'ValueType', 'ParentLocationCode', 'ParentLocation', 'Location type', 'SpatialDimValueCode', 'Period type', 'IsLatestYear', 'FactValueTranslationID', 'FactComments', 'Language', 'DateModified']\n",
        "screening_method_cleaned = screening_method_cleaned.drop(columns=screening_method_columns_to_drop)\n",
        "screening_method_cleaned.rename(columns={'Value': 'ScreeningValue'}, inplace=True)\n",
        "# print(screening_method_cleaned.head())\n",
        "screening_method_cleaned.to_csv('screening_method_cleaned.csv', index=False)\n",
        "\n",
        "#Disability_adjusted_life_yrs\n",
        "disability_adjusted_life_yrs_cleaned = disability_adjusted_life_yrs.dropna(axis=1, how='all')\n",
        "disability_adjusted_columns_to_drop = ['measure_id', 'measure_name', 'location_id', 'sex_id', 'sex_name', 'age_id', 'cause_id', 'cause_name', 'rei_id', 'rei_name', 'metric_id', 'metric_name', 'year', 'upper', 'lower']\n",
        "disability_adjusted_life_yrs_cleaned = disability_adjusted_life_yrs_cleaned.drop(columns=disability_adjusted_columns_to_drop)\n",
        "disability_adjusted_life_yrs_cleaned.rename(columns={'val': 'Disability_Adjusted_Life_Yrs_Value', 'location_name': 'Location'}, inplace=True)\n",
        "# print(disability_adjusted_life_yrs_cleaned.head())\n",
        "disability_adjusted_life_yrs_cleaned.to_csv('disability_adjusted_life_yrs_cleaned.csv', index=False)\n",
        "\n",
        "#Years_lived_with_disability\n",
        "yrs_lived_with_disability_cleaned = years_lived_with_disability.dropna(axis=1, how='all')\n",
        "yrs_lived_with_disability_columns_to_drop = ['measure_id', 'measure_name', 'location_id', 'sex_id', 'sex_name', 'age_id', 'cause_id', 'cause_name', 'rei_id', 'rei_name', 'metric_id', 'metric_name', 'year', 'upper', 'lower']\n",
        "yrs_lived_with_disability_cleaned = yrs_lived_with_disability_cleaned.drop(columns=yrs_lived_with_disability_columns_to_drop)\n",
        "yrs_lived_with_disability_cleaned.rename(columns={'val': 'Yrs_Lived_With_Disability_Value', 'location_name': 'Location'}, inplace=True)\n",
        "# print(yrs_lived_with_disability_cleaned.head())\n",
        "yrs_lived_with_disability_cleaned.to_csv('yrs_lived_with_disability_cleaned.csv', index=False)\n",
        "\n",
        "#Years_lost_with_disability\n",
        "yrs_lost_with_disability_cleaned = years_lost_with_disability.dropna(axis=1, how='all')\n",
        "yrs_lost_with_disability_columns_to_drop = ['measure_id', 'measure_name', 'location_id', 'sex_id', 'sex_name', 'age_id', 'cause_id', 'cause_name', 'rei_id', 'rei_name', 'metric_id', 'metric_name', 'year', 'upper', 'lower']\n",
        "yrs_lost_with_disability_cleaned = yrs_lost_with_disability_cleaned.drop(columns=yrs_lost_with_disability_columns_to_drop)\n",
        "yrs_lost_with_disability_cleaned.rename(columns={'val': 'Yrs_Lost_With_Disability_Value', 'location_name': 'Location'}, inplace=True)\n",
        "# print(yrs_lost_with_disability_cleaned.head())\n",
        "yrs_lost_with_disability_cleaned.to_csv('yrs_lost_with_disability_cleaned.csv', index=False)\n",
        "\n",
        "#Prevalence_of_cancer\n",
        "prevalence_of_cancer_cleaned = prevalence_of_cancer.dropna(axis=1, how='all')\n",
        "prevalence_of_cancer_columns_to_drop = ['measure_id', 'measure_name', 'location_id', 'sex_id', 'sex_name', 'age_id', 'cause_id', 'cause_name', 'metric_id', 'metric_name', 'year', 'upper', 'lower']\n",
        "prevalence_of_cancer_cleaned = prevalence_of_cancer_cleaned.drop(columns=prevalence_of_cancer_columns_to_drop)\n",
        "prevalence_of_cancer_cleaned.rename(columns={'location_name': 'Location', 'val':'Prevalence_of_cancer_value'}, inplace=True)\n",
        "# print(prevalence_of_cancer_cleaned.head())\n",
        "prevalence_of_cancer_cleaned.to_csv('prevalence_of_cancer_cleaned.csv', index=False)\n",
        "\n",
        "#Incidence_of_cancer\n",
        "incidence_of_cancer_cleaned = incidence_of_cancer.dropna(axis=1, how='all')\n",
        "incidence_of_cancer_columns_to_drop = ['measure_id', 'measure_name', 'location_id', 'sex_id', 'sex_name', 'age_id', 'cause_id', 'cause_name', 'metric_id', 'metric_name', 'year', 'upper', 'lower']\n",
        "incidence_of_cancer_cleaned = incidence_of_cancer_cleaned.drop(columns=prevalence_of_cancer_columns_to_drop)\n",
        "incidence_of_cancer_cleaned.rename(columns={'location_name': 'Location', 'val':'Incidence_of_cancer_value'}, inplace=True)\n",
        "# print(incidence_of_cancer_cleaned.head())\n",
        "incidence_of_cancer_cleaned.to_csv('incidence_of_cancer_cleaned.csv', index=False)\n",
        "\n",
        "# Merging datasets on the 'Location' column\n",
        "merged_df1 = coverage_cleaned.merge(prevalence_cleaned, on='Location', how='outer').merge(screening_method_cleaned, on='Location', how='outer')\n",
        "merged_df1.to_csv('merged_dataset.csv', index=False)\n",
        "# print(merged_df.head())\n",
        "\n",
        "merged_df2 = pd.merge(disability_adjusted_life_yrs_cleaned, mortality_cleaned, on=['Location', 'age_name'], how='outer')\n",
        "merged_df2 = pd.merge(merged_df2, yrs_lived_with_disability_cleaned, on=['Location', 'age_name'], how='outer')\n",
        "merged_df2 = pd.merge(merged_df2, yrs_lost_with_disability_cleaned, on=['Location', 'age_name'], how='outer')\n",
        "merged_df2 = pd.merge(merged_df2, prevalence_of_cancer_cleaned, on=['Location', 'age_name'], how='outer')\n",
        "merged_df2 = pd.merge(merged_df2, incidence_of_cancer_cleaned, on=['Location', 'age_name'], how='outer')\n",
        "final_df = pd.merge(merged_df1, merged_df2, on='Location', how='left')\n",
        "# print(final_df.head())\n",
        "\n",
        "unwanted_values = [\"Not applicable\", \"Don't know\", \"No response\"]\n",
        "final_df = final_df[\n",
        "    (~final_df['CoverageValue'].isin(unwanted_values)) &\n",
        "    (~final_df['ScreeningValue'].isin(unwanted_values))\n",
        "]\n",
        "final_df = final_df.dropna(axis=1, how='all')\n",
        "final_df = final_df.dropna(subset=['Mortality_val'])\n",
        "final_df.loc[final_df['CoverageValue'] == 'Less than 10', 'CoverageFactValueNumericLow'] = 0\n",
        "final_df.loc[final_df['CoverageValue'] == 'Less than 10', 'CoverageFactValueNumericHigh'] = 10\n",
        "final_df.loc[final_df['CoverageValue'] == '70 or more', 'CoverageFactValueNumericLow'] = 70\n",
        "final_df.loc[final_df['CoverageValue'] == '70 or more', 'CoverageFactValueNumericHigh'] = 100\n",
        "\n",
        "final_df.to_csv('final_clean_dataset.csv', index=False)\n",
        "# print(final_df.head())\n",
        "\n",
        "# Selecting the columns we want to scale (excluding categorical variables if needed)\n",
        "numerical_features = ['CoverageFactValueNumericLow', 'CoverageFactValueNumericHigh', 'PrevalenceFactValueNumeric', 'Disability_Adjusted_Life_Yrs_Value',\n",
        "                      'Mortality_val', 'Yrs_Lived_With_Disability_Value', 'Yrs_Lost_With_Disability_Value', 'Prevalence_of_cancer_value',\n",
        "                      'Incidence_of_cancer_value']\n",
        "\n",
        "# Initialize MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Apply Min-Max scaling to the selected columns\n",
        "final_df[numerical_features] = scaler.fit_transform(final_df[numerical_features])\n",
        "\n",
        "# final_df.head()\n",
        "\n",
        "final_df.to_csv('final_clean_dataset_standardized.csv', index=False)\n",
        "\n",
        "saved_data = final_df\n",
        "\n",
        "# print(list(saved_data.columns))\n",
        "saved_data = saved_data.drop(['Location', 'CoverageValue', 'age_name', 'CoverageFactValueNumericLow', 'CoverageFactValueNumericHigh', 'ScreeningValue'], axis=1)\n",
        "\n",
        "agg_cluster = AgglomerativeClustering(n_clusters=None, distance_threshold=0, linkage='ward')\n",
        "agg_cluster_labels = agg_cluster.fit_predict(saved_data)\n",
        "saved_data['Agglomerative_Cluster'] = agg_cluster_labels\n",
        "\n",
        "# Visualize the dendrogram for Agglomerative Clustering\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.title(\"Dendrogram for Agglomerative Clustering\")\n",
        "dend = shc.dendrogram(shc.linkage(saved_data, method='ward'))\n",
        "\n",
        "plt.show()\n",
        "\n",
        "'''\n",
        "Duc Dung Le\n",
        "K-Means clustering\n",
        "'''\n",
        "def read_file(filepath: str, header: int, sep: str):\n",
        "    data = pd.read_csv(\n",
        "        filepath,\n",
        "        header=header,\n",
        "        sep=sep\n",
        "        # encoding='utf-16-be'\n",
        "    )\n",
        "    return data\n",
        "\n",
        "def task_kMeans():\n",
        "    data = read_file(\n",
        "        filepath='/content/final_clean_dataset_standardized.csv',\n",
        "        header=0,\n",
        "        sep=','\n",
        "    )\n",
        "    unique_coverage = data['CoverageValue'].unique()\n",
        "    print(unique_coverage)\n",
        "    unique_method = data['ScreeningValue'].unique()\n",
        "    print(unique_method)\n",
        "    plt.scatter(data['PrevalenceFactValueNumeric'], data['Prevalence_of_cancer_value'], cmap='viridis')\n",
        "    plt.title(label='Dataset')\n",
        "    plt.xlabel(xlabel='Prevalence to screening methods')\n",
        "    plt.ylabel(ylabel='Prevalence to cancer')\n",
        "    plt.show()\n",
        "    plt.savefig('/content/fig0.png')\n",
        "    min_max_data = data.copy()\n",
        "    min_max_data[\n",
        "        [\n",
        "            'PrevalenceFactValueNumeric',\n",
        "            'Prevalence_of_cancer_value',\n",
        "            'Yrs_Lived_With_Disability_Value',\n",
        "            'Yrs_Lost_With_Disability_Value',\n",
        "            'Incidence_of_cancer_value',\n",
        "            'Disability_Adjusted_Life_Yrs_Value',\n",
        "            'Mortality_val'\n",
        "        ]\n",
        "    ] = MinMaxScaler().fit_transform(\n",
        "        data[\n",
        "            [\n",
        "                'PrevalenceFactValueNumeric',\n",
        "                'Prevalence_of_cancer_value',\n",
        "                'Yrs_Lived_With_Disability_Value',\n",
        "                'Yrs_Lost_With_Disability_Value',\n",
        "                'Incidence_of_cancer_value',\n",
        "                'Disability_Adjusted_Life_Yrs_Value',\n",
        "                'Mortality_val'\n",
        "            ]\n",
        "        ]\n",
        "    )\n",
        "    min_max_clustering = min_max_data[\n",
        "        [\n",
        "            'PrevalenceFactValueNumeric',\n",
        "            'Prevalence_of_cancer_value',\n",
        "            'Yrs_Lived_With_Disability_Value',\n",
        "            'Yrs_Lost_With_Disability_Value',\n",
        "            'Incidence_of_cancer_value',\n",
        "            'Disability_Adjusted_Life_Yrs_Value',\n",
        "            'Mortality_val'\n",
        "        ]\n",
        "    ]\n",
        "    choices = [3,4]\n",
        "\n",
        "    kmeans = KMeans(n_clusters = 4)\n",
        "    kmeans.fit(min_max_clustering)\n",
        "    labels = kmeans.labels_\n",
        "    plt.scatter(min_max_clustering['PrevalenceFactValueNumeric'], min_max_clustering['Prevalence_of_cancer_value'], c=labels, cmap='viridis')\n",
        "    plt.title(label='Prevalence to screening methods + Prevalence to cancer')\n",
        "    plt.xlabel(xlabel='Prevalence to screening methods')\n",
        "    plt.ylabel(ylabel='Prevalence to cancer')\n",
        "    plt.savefig('/content/fig1.png')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    # prevalence fact + Incidence_of_cancer_value\n",
        "    plt.scatter(min_max_clustering['PrevalenceFactValueNumeric'], min_max_clustering['Incidence_of_cancer_value'], c=labels, cmap='viridis')\n",
        "    plt.title(label='Prevalence to screening methods + Incidence to cancer')\n",
        "    plt.xlabel(xlabel='Prevalence to screening methods')\n",
        "    plt.ylabel(ylabel='Incidence to cancer')\n",
        "    plt.savefig('/content/fig2.png')\n",
        "    plt.show()\n",
        "\n",
        "    # prevalance fact + Yrs_Lived_With_Disability_Value\n",
        "    plt.scatter(min_max_clustering['PrevalenceFactValueNumeric'], min_max_clustering['Yrs_Lived_With_Disability_Value'], c=labels, cmap='viridis')\n",
        "    plt.title(label='Prevalence to screening methods + Years lived with disability')\n",
        "    plt.xlabel(xlabel='Prevalence to screening methods')\n",
        "    plt.ylabel(ylabel='Years lived with disability')\n",
        "    plt.savefig('/content/fig3.png')\n",
        "    plt.show()\n",
        "\n",
        "     # prevalance fact + Mortality_val\n",
        "    plt.scatter(min_max_clustering['PrevalenceFactValueNumeric'], min_max_clustering['Mortality_val'], c=labels, cmap='viridis')\n",
        "    plt.title(label='Prevalence to screening methods + Mortality_val clustering')\n",
        "    plt.xlabel(xlabel='Prevalence to screening methods')\n",
        "    plt.ylabel(ylabel='Mortality percentage')\n",
        "    plt.savefig('/content/fig4.png')\n",
        "    plt.show()\n",
        "\n",
        "task_kMeans()\n",
        "\n",
        "#Lukas\n",
        "\n",
        "data = pd.read_csv(\"/content/final_clean_dataset_standardized.csv\", delimiter=\",\")\n",
        "\n",
        "data = data.drop(['Location', 'CoverageValue', 'age_name', 'CoverageFactValueNumericLow','CoverageFactValueNumericHigh'], axis=1)\n",
        "\n",
        "\n",
        "data = data.drop(['ScreeningValue'], axis=1)\n",
        "dbscan = DBSCAN(eps=0.15, min_samples=5)\n",
        "clusters = dbscan.fit(data).labels_\n",
        "plt.scatter(data[\"PrevalenceFactValueNumeric\"], data[\"Prevalence_of_cancer_value\"],c=clusters)\n",
        "plt.xlabel(\"Prevalence of screening\")\n",
        "plt.ylabel(\"Prevalence of cancer\")\n",
        "plt.show()\n",
        "\n",
        "plt.scatter(data[\"PrevalenceFactValueNumeric\"], data[\"Incidence_of_cancer_value\"],c=clusters)\n",
        "plt.xlabel(\"Prevalence of screening\")\n",
        "plt.ylabel(\"Incidence of cancer\")\n",
        "plt.show()\n",
        "\n",
        "plt.scatter(data[\"PrevalenceFactValueNumeric\"], data[\"Yrs_Lived_With_Disability_Value\"],c=clusters)\n",
        "plt.xlabel(\"Prevalence of screening\")\n",
        "plt.ylabel(\"Years lived with disability\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.scatter(data[\"PrevalenceFactValueNumeric\"], data[\"Mortality_val\"],c=clusters)\n",
        "plt.xlabel(\"Prevalence of screening\")\n",
        "plt.ylabel(\"Mortality\")\n",
        "plt.show()"
      ]
    }
  ]
}